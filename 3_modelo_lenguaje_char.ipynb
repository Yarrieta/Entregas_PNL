{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yarrieta/Entregas_PNL/blob/Desafio3/3_modelo_lenguaje_char.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout, GRU\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7amy6uUaBLVD"
      },
      "outputs": [],
      "source": [
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [],
      "source": [
        "raw_html = urllib.request.urlopen('https://www.textos.info/julio-verne/la-vuelta-al-mundo-en-80-dias/ebook')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Parsear artículo, 'lxml' es el parser a utilizar\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "# Encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
        "# y tenerlos disponible como lista\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text + ' '\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "WBE0sSYuB-E6",
        "outputId": "b81eb309-b4ab-4e5d-9d22-a9a652f006a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' en el año 1872, la casa número 7 de saville-row, burlington gardens \\r\\n—donde murió sheridan en 1814— estaba habitada por phileas fogg, quien a\\r\\n pesar de que parecía haber tomado el partido de no hacer nada que \\r\\npudiese llamar la atención, era uno de los miembros más notables y \\r\\nsingulares del reformclub de londres. por consiguiente, phileas fogg, personaje enigmático y del cual sólo \\r\\nse sabía que era un hombre muy galante y de los más cumplidos gentlemen \\r\\nde la alta sociedad inglesa, sucedía a uno de los más grandes oradores \\r\\nque honran a inglaterra. decíase que se daba un aire a lo byron —su cabeza, se entiende, \\r\\nporque, en cuanto a los pies, no tenía defecto alguno—, pero a un byron \\r\\nde bigote y pastillas, a un byron impasible, que hubiera vivido mil años\\r\\n sin envejecer. phileas fogg, era inglés de pura cepa; pero quizás no había nacido en\\r\\n londres. jamás se le había visto en la bolsa ni en el banco, ni en \\r\\nninguno de los despachos mercantiles de la city. ni las dársenas '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwTK6xgLJd8q",
        "outputId": "3ff62890-6d38-4f8c-ac73-a62c49c9ab24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLF_3VYIqKLh",
        "outputId": "97c0da19-1b78-4e2d-8ae9-60436f669a93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'b': 0,\n",
              " '2': 1,\n",
              " '?': 2,\n",
              " 'ü': 3,\n",
              " '9': 4,\n",
              " 'u': 5,\n",
              " '\\n': 6,\n",
              " '4': 7,\n",
              " 'é': 8,\n",
              " 'è': 9,\n",
              " 'w': 10,\n",
              " 'o': 11,\n",
              " '3': 12,\n",
              " '\\r': 13,\n",
              " '6': 14,\n",
              " '>': 15,\n",
              " 'e': 16,\n",
              " ':': 17,\n",
              " '!': 18,\n",
              " '8': 19,\n",
              " '»': 20,\n",
              " 'ó': 21,\n",
              " '\\t': 22,\n",
              " 'h': 23,\n",
              " 'g': 24,\n",
              " 'q': 25,\n",
              " '<': 26,\n",
              " 'a': 27,\n",
              " 'r': 28,\n",
              " \"'\": 29,\n",
              " '—': 30,\n",
              " '.': 31,\n",
              " 'z': 32,\n",
              " 'n': 33,\n",
              " 'c': 34,\n",
              " ';': 35,\n",
              " '1': 36,\n",
              " ' ': 37,\n",
              " 's': 38,\n",
              " 'p': 39,\n",
              " '¿': 40,\n",
              " '5': 41,\n",
              " 'á': 42,\n",
              " '\"': 43,\n",
              " 'j': 44,\n",
              " 'í': 45,\n",
              " '~': 46,\n",
              " 'i': 47,\n",
              " '7': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'd': 51,\n",
              " '-': 52,\n",
              " 'm': 53,\n",
              " '/': 54,\n",
              " '«': 55,\n",
              " ',': 56,\n",
              " 'v': 57,\n",
              " 'y': 58,\n",
              " 'ú': 59,\n",
              " 'ñ': 60,\n",
              " '(': 61,\n",
              " '0': 62,\n",
              " 'x': 63,\n",
              " 't': 64,\n",
              " ')': 65,\n",
              " 'f': 66,\n",
              " '¡': 67}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "char2idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwGVSKOiJ5bj",
        "outputId": "3e836431-9aed-4569-ace7-5ab2c4d6fbfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37,\n",
              " 16,\n",
              " 33,\n",
              " 37,\n",
              " 16,\n",
              " 50,\n",
              " 37,\n",
              " 27,\n",
              " 60,\n",
              " 11,\n",
              " 37,\n",
              " 36,\n",
              " 19,\n",
              " 48,\n",
              " 1,\n",
              " 56,\n",
              " 37,\n",
              " 50,\n",
              " 27,\n",
              " 37,\n",
              " 34,\n",
              " 27,\n",
              " 38,\n",
              " 27,\n",
              " 37,\n",
              " 33,\n",
              " 59,\n",
              " 53,\n",
              " 16,\n",
              " 28,\n",
              " 11,\n",
              " 37,\n",
              " 48,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 38,\n",
              " 27,\n",
              " 57,\n",
              " 47,\n",
              " 50,\n",
              " 50,\n",
              " 16,\n",
              " 52,\n",
              " 28,\n",
              " 11,\n",
              " 10,\n",
              " 56,\n",
              " 37,\n",
              " 0,\n",
              " 5,\n",
              " 28,\n",
              " 50,\n",
              " 47,\n",
              " 33,\n",
              " 24,\n",
              " 64,\n",
              " 11,\n",
              " 33,\n",
              " 37,\n",
              " 24,\n",
              " 27,\n",
              " 28,\n",
              " 51,\n",
              " 16,\n",
              " 33,\n",
              " 38,\n",
              " 37,\n",
              " 13,\n",
              " 6,\n",
              " 30,\n",
              " 51,\n",
              " 11,\n",
              " 33,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 53,\n",
              " 5,\n",
              " 28,\n",
              " 47,\n",
              " 21,\n",
              " 37,\n",
              " 38,\n",
              " 23,\n",
              " 16,\n",
              " 28,\n",
              " 47,\n",
              " 51,\n",
              " 27,\n",
              " 33,\n",
              " 37,\n",
              " 16,\n",
              " 33,\n",
              " 37,\n",
              " 36,\n",
              " 19,\n",
              " 36,\n",
              " 7,\n",
              " 30,\n",
              " 37,\n",
              " 16,\n",
              " 38,\n",
              " 64,\n",
              " 27,\n",
              " 0,\n",
              " 27,\n",
              " 37,\n",
              " 23,\n",
              " 27,\n",
              " 0,\n",
              " 47,\n",
              " 64,\n",
              " 27,\n",
              " 51,\n",
              " 27,\n",
              " 37,\n",
              " 39,\n",
              " 11,\n",
              " 28,\n",
              " 37,\n",
              " 39,\n",
              " 23,\n",
              " 47,\n",
              " 50,\n",
              " 16,\n",
              " 27,\n",
              " 38,\n",
              " 37,\n",
              " 66,\n",
              " 11,\n",
              " 24,\n",
              " 24,\n",
              " 56,\n",
              " 37,\n",
              " 25,\n",
              " 5,\n",
              " 47,\n",
              " 16,\n",
              " 33,\n",
              " 37,\n",
              " 27,\n",
              " 13,\n",
              " 6,\n",
              " 37,\n",
              " 39,\n",
              " 16,\n",
              " 38,\n",
              " 27,\n",
              " 28,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 25,\n",
              " 5,\n",
              " 16,\n",
              " 37,\n",
              " 39,\n",
              " 27,\n",
              " 28,\n",
              " 16,\n",
              " 34,\n",
              " 45,\n",
              " 27,\n",
              " 37,\n",
              " 23,\n",
              " 27,\n",
              " 0,\n",
              " 16,\n",
              " 28,\n",
              " 37,\n",
              " 64,\n",
              " 11,\n",
              " 53,\n",
              " 27,\n",
              " 51,\n",
              " 11,\n",
              " 37,\n",
              " 16,\n",
              " 50,\n",
              " 37,\n",
              " 39,\n",
              " 27,\n",
              " 28,\n",
              " 64,\n",
              " 47,\n",
              " 51,\n",
              " 11,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 33,\n",
              " 11,\n",
              " 37,\n",
              " 23,\n",
              " 27,\n",
              " 34,\n",
              " 16,\n",
              " 28,\n",
              " 37,\n",
              " 33,\n",
              " 27,\n",
              " 51,\n",
              " 27,\n",
              " 37,\n",
              " 25,\n",
              " 5,\n",
              " 16,\n",
              " 37,\n",
              " 13,\n",
              " 6,\n",
              " 39,\n",
              " 5,\n",
              " 51,\n",
              " 47,\n",
              " 16,\n",
              " 38,\n",
              " 16,\n",
              " 37,\n",
              " 50,\n",
              " 50,\n",
              " 27,\n",
              " 53,\n",
              " 27,\n",
              " 28,\n",
              " 37,\n",
              " 50,\n",
              " 27,\n",
              " 37,\n",
              " 27,\n",
              " 64,\n",
              " 16,\n",
              " 33,\n",
              " 34,\n",
              " 47,\n",
              " 21,\n",
              " 33,\n",
              " 56,\n",
              " 37,\n",
              " 16,\n",
              " 28,\n",
              " 27,\n",
              " 37,\n",
              " 5,\n",
              " 33,\n",
              " 11,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 50,\n",
              " 11,\n",
              " 38,\n",
              " 37,\n",
              " 53,\n",
              " 47,\n",
              " 16,\n",
              " 53,\n",
              " 0,\n",
              " 28,\n",
              " 11,\n",
              " 38,\n",
              " 37,\n",
              " 53,\n",
              " 42,\n",
              " 38,\n",
              " 37,\n",
              " 33,\n",
              " 11,\n",
              " 64,\n",
              " 27,\n",
              " 0,\n",
              " 50,\n",
              " 16,\n",
              " 38,\n",
              " 37,\n",
              " 58,\n",
              " 37,\n",
              " 13,\n",
              " 6,\n",
              " 38,\n",
              " 47,\n",
              " 33,\n",
              " 24,\n",
              " 5,\n",
              " 50,\n",
              " 27,\n",
              " 28,\n",
              " 16,\n",
              " 38,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 50,\n",
              " 37,\n",
              " 28,\n",
              " 16,\n",
              " 66,\n",
              " 11,\n",
              " 28,\n",
              " 53,\n",
              " 34,\n",
              " 50,\n",
              " 5,\n",
              " 0,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 50,\n",
              " 11,\n",
              " 33,\n",
              " 51,\n",
              " 28,\n",
              " 16,\n",
              " 38,\n",
              " 31,\n",
              " 37,\n",
              " 39,\n",
              " 11,\n",
              " 28,\n",
              " 37,\n",
              " 34,\n",
              " 11,\n",
              " 33,\n",
              " 38,\n",
              " 47,\n",
              " 24,\n",
              " 5,\n",
              " 47,\n",
              " 16,\n",
              " 33,\n",
              " 64,\n",
              " 16,\n",
              " 56,\n",
              " 37,\n",
              " 39,\n",
              " 23,\n",
              " 47,\n",
              " 50,\n",
              " 16,\n",
              " 27,\n",
              " 38,\n",
              " 37,\n",
              " 66,\n",
              " 11,\n",
              " 24,\n",
              " 24,\n",
              " 56,\n",
              " 37,\n",
              " 39,\n",
              " 16,\n",
              " 28,\n",
              " 38,\n",
              " 11,\n",
              " 33,\n",
              " 27,\n",
              " 44,\n",
              " 16,\n",
              " 37,\n",
              " 16,\n",
              " 33,\n",
              " 47,\n",
              " 24,\n",
              " 53,\n",
              " 42,\n",
              " 64,\n",
              " 47,\n",
              " 34,\n",
              " 11,\n",
              " 37,\n",
              " 58,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 50,\n",
              " 37,\n",
              " 34,\n",
              " 5,\n",
              " 27,\n",
              " 50,\n",
              " 37,\n",
              " 38,\n",
              " 21,\n",
              " 50,\n",
              " 11,\n",
              " 37,\n",
              " 13,\n",
              " 6,\n",
              " 38,\n",
              " 16,\n",
              " 37,\n",
              " 38,\n",
              " 27,\n",
              " 0,\n",
              " 45,\n",
              " 27,\n",
              " 37,\n",
              " 25,\n",
              " 5,\n",
              " 16,\n",
              " 37,\n",
              " 16,\n",
              " 28,\n",
              " 27,\n",
              " 37,\n",
              " 5,\n",
              " 33,\n",
              " 37,\n",
              " 23,\n",
              " 11,\n",
              " 53,\n",
              " 0,\n",
              " 28,\n",
              " 16,\n",
              " 37,\n",
              " 53,\n",
              " 5,\n",
              " 58,\n",
              " 37,\n",
              " 24,\n",
              " 27,\n",
              " 50,\n",
              " 27,\n",
              " 33,\n",
              " 64,\n",
              " 16,\n",
              " 37,\n",
              " 58,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 50,\n",
              " 11,\n",
              " 38,\n",
              " 37,\n",
              " 53,\n",
              " 42,\n",
              " 38,\n",
              " 37,\n",
              " 34,\n",
              " 5,\n",
              " 53,\n",
              " 39,\n",
              " 50,\n",
              " 47,\n",
              " 51,\n",
              " 11,\n",
              " 38,\n",
              " 37,\n",
              " 24,\n",
              " 16,\n",
              " 33,\n",
              " 64,\n",
              " 50,\n",
              " 16,\n",
              " 53,\n",
              " 16,\n",
              " 33,\n",
              " 37,\n",
              " 13,\n",
              " 6,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 50,\n",
              " 27,\n",
              " 37,\n",
              " 27,\n",
              " 50,\n",
              " 64,\n",
              " 27,\n",
              " 37,\n",
              " 38,\n",
              " 11,\n",
              " 34,\n",
              " 47,\n",
              " 16,\n",
              " 51,\n",
              " 27,\n",
              " 51,\n",
              " 37,\n",
              " 47,\n",
              " 33,\n",
              " 24,\n",
              " 50,\n",
              " 16,\n",
              " 38,\n",
              " 27,\n",
              " 56,\n",
              " 37,\n",
              " 38,\n",
              " 5,\n",
              " 34,\n",
              " 16,\n",
              " 51,\n",
              " 45,\n",
              " 27,\n",
              " 37,\n",
              " 27,\n",
              " 37,\n",
              " 5,\n",
              " 33,\n",
              " 11,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 50,\n",
              " 11,\n",
              " 38,\n",
              " 37,\n",
              " 53,\n",
              " 42,\n",
              " 38,\n",
              " 37,\n",
              " 24,\n",
              " 28,\n",
              " 27,\n",
              " 33,\n",
              " 51,\n",
              " 16,\n",
              " 38,\n",
              " 37,\n",
              " 11,\n",
              " 28,\n",
              " 27,\n",
              " 51,\n",
              " 11,\n",
              " 28,\n",
              " 16,\n",
              " 38,\n",
              " 37,\n",
              " 13,\n",
              " 6,\n",
              " 25,\n",
              " 5,\n",
              " 16,\n",
              " 37,\n",
              " 23,\n",
              " 11,\n",
              " 33,\n",
              " 28,\n",
              " 27,\n",
              " 33,\n",
              " 37,\n",
              " 27,\n",
              " 37,\n",
              " 47,\n",
              " 33,\n",
              " 24,\n",
              " 50,\n",
              " 27,\n",
              " 64,\n",
              " 16,\n",
              " 28,\n",
              " 28,\n",
              " 27,\n",
              " 31,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 34,\n",
              " 45,\n",
              " 27,\n",
              " 38,\n",
              " 16,\n",
              " 37,\n",
              " 25,\n",
              " 5,\n",
              " 16,\n",
              " 37,\n",
              " 38,\n",
              " 16,\n",
              " 37,\n",
              " 51,\n",
              " 27,\n",
              " 0,\n",
              " 27,\n",
              " 37,\n",
              " 5,\n",
              " 33,\n",
              " 37,\n",
              " 27,\n",
              " 47,\n",
              " 28,\n",
              " 16,\n",
              " 37,\n",
              " 27,\n",
              " 37,\n",
              " 50,\n",
              " 11,\n",
              " 37,\n",
              " 0,\n",
              " 58,\n",
              " 28,\n",
              " 11,\n",
              " 33,\n",
              " 37,\n",
              " 30,\n",
              " 38,\n",
              " 5,\n",
              " 37,\n",
              " 34,\n",
              " 27,\n",
              " 0,\n",
              " 16,\n",
              " 32,\n",
              " 27,\n",
              " 56,\n",
              " 37,\n",
              " 38,\n",
              " 16,\n",
              " 37,\n",
              " 16,\n",
              " 33,\n",
              " 64,\n",
              " 47,\n",
              " 16,\n",
              " 33,\n",
              " 51,\n",
              " 16,\n",
              " 56,\n",
              " 37,\n",
              " 13,\n",
              " 6,\n",
              " 39,\n",
              " 11,\n",
              " 28,\n",
              " 25,\n",
              " 5,\n",
              " 16,\n",
              " 56,\n",
              " 37,\n",
              " 16,\n",
              " 33,\n",
              " 37,\n",
              " 34,\n",
              " 5,\n",
              " 27,\n",
              " 33,\n",
              " 64,\n",
              " 11,\n",
              " 37,\n",
              " 27,\n",
              " 37,\n",
              " 50,\n",
              " 11,\n",
              " 38,\n",
              " 37,\n",
              " 39,\n",
              " 47,\n",
              " 16,\n",
              " 38,\n",
              " 56,\n",
              " 37,\n",
              " 33,\n",
              " 11,\n",
              " 37,\n",
              " 64,\n",
              " 16,\n",
              " 33,\n",
              " 45,\n",
              " 27,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 66,\n",
              " 16,\n",
              " 34,\n",
              " 64,\n",
              " 11,\n",
              " 37,\n",
              " 27,\n",
              " 50,\n",
              " 24,\n",
              " 5,\n",
              " 33,\n",
              " 11,\n",
              " 30,\n",
              " 56,\n",
              " 37,\n",
              " 39,\n",
              " 16,\n",
              " 28,\n",
              " 11,\n",
              " 37,\n",
              " 27,\n",
              " 37,\n",
              " 5,\n",
              " 33,\n",
              " 37,\n",
              " 0,\n",
              " 58,\n",
              " 28,\n",
              " 11,\n",
              " 33,\n",
              " 37,\n",
              " 13,\n",
              " 6,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 0,\n",
              " 47,\n",
              " 24,\n",
              " 11,\n",
              " 64,\n",
              " 16,\n",
              " 37,\n",
              " 58,\n",
              " 37,\n",
              " 39,\n",
              " 27,\n",
              " 38,\n",
              " 64,\n",
              " 47,\n",
              " 50,\n",
              " 50,\n",
              " 27,\n",
              " 38,\n",
              " 56,\n",
              " 37,\n",
              " 27,\n",
              " 37,\n",
              " 5,\n",
              " 33,\n",
              " 37,\n",
              " 0,\n",
              " 58,\n",
              " 28,\n",
              " 11,\n",
              " 33,\n",
              " 37,\n",
              " 47,\n",
              " 53,\n",
              " 39,\n",
              " 27,\n",
              " 38,\n",
              " 47,\n",
              " 0,\n",
              " 50,\n",
              " 16,\n",
              " 56,\n",
              " 37,\n",
              " 25,\n",
              " 5,\n",
              " 16,\n",
              " 37,\n",
              " 23,\n",
              " 5,\n",
              " 0,\n",
              " 47,\n",
              " 16,\n",
              " 28,\n",
              " 27,\n",
              " 37,\n",
              " 57,\n",
              " 47,\n",
              " 57,\n",
              " 47,\n",
              " 51,\n",
              " 11,\n",
              " 37,\n",
              " 53,\n",
              " 47,\n",
              " 50,\n",
              " 37,\n",
              " 27,\n",
              " 60,\n",
              " 11,\n",
              " 38,\n",
              " 13,\n",
              " 6,\n",
              " 37,\n",
              " 38,\n",
              " 47,\n",
              " 33,\n",
              " 37,\n",
              " 16,\n",
              " 33,\n",
              " 57,\n",
              " 16,\n",
              " 44,\n",
              " 16,\n",
              " 34,\n",
              " 16,\n",
              " 28,\n",
              " 31,\n",
              " 37,\n",
              " 39,\n",
              " 23,\n",
              " 47,\n",
              " 50,\n",
              " 16,\n",
              " 27,\n",
              " 38,\n",
              " 37,\n",
              " 66,\n",
              " 11,\n",
              " 24,\n",
              " 24,\n",
              " 56,\n",
              " 37,\n",
              " 16,\n",
              " 28,\n",
              " 27,\n",
              " 37,\n",
              " 47,\n",
              " 33,\n",
              " 24,\n",
              " 50,\n",
              " 8,\n",
              " 38,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 39,\n",
              " 5,\n",
              " 28,\n",
              " 27,\n",
              " 37,\n",
              " 34,\n",
              " 16,\n",
              " 39,\n",
              " 27,\n",
              " 35,\n",
              " 37,\n",
              " 39,\n",
              " 16,\n",
              " 28,\n",
              " 11,\n",
              " 37,\n",
              " 25,\n",
              " 5,\n",
              " 47,\n",
              " 32,\n",
              " 42,\n",
              " 38,\n",
              " 37,\n",
              " 33,\n",
              " 11,\n",
              " 37,\n",
              " 23,\n",
              " 27,\n",
              " 0,\n",
              " 45,\n",
              " 27,\n",
              " 37,\n",
              " 33,\n",
              " 27,\n",
              " 34,\n",
              " 47,\n",
              " 51,\n",
              " 11,\n",
              " 37,\n",
              " 16,\n",
              " 33,\n",
              " 13,\n",
              " 6,\n",
              " 37,\n",
              " 50,\n",
              " 11,\n",
              " 33,\n",
              " 51,\n",
              " 28,\n",
              " 16,\n",
              " 38,\n",
              " 31,\n",
              " 37,\n",
              " 44,\n",
              " 27,\n",
              " 53,\n",
              " 42,\n",
              " 38,\n",
              " 37,\n",
              " 38,\n",
              " 16,\n",
              " 37,\n",
              " 50,\n",
              " 16,\n",
              " 37,\n",
              " 23,\n",
              " 27,\n",
              " 0,\n",
              " 45,\n",
              " 27,\n",
              " 37,\n",
              " 57,\n",
              " 47,\n",
              " 38,\n",
              " 64,\n",
              " 11,\n",
              " 37,\n",
              " 16,\n",
              " 33,\n",
              " 37,\n",
              " 50,\n",
              " 27,\n",
              " 37,\n",
              " 0,\n",
              " 11,\n",
              " 50,\n",
              " 38,\n",
              " 27,\n",
              " 37,\n",
              " 33,\n",
              " 47,\n",
              " 37,\n",
              " 16,\n",
              " 33,\n",
              " 37,\n",
              " 16,\n",
              " 50,\n",
              " 37,\n",
              " 0,\n",
              " 27,\n",
              " 33,\n",
              " 34,\n",
              " 11,\n",
              " 56,\n",
              " 37,\n",
              " 33,\n",
              " 47,\n",
              " 37,\n",
              " 16,\n",
              " 33,\n",
              " 37,\n",
              " 13,\n",
              " 6,\n",
              " 33,\n",
              " 47,\n",
              " 33,\n",
              " 24,\n",
              " 5,\n",
              " 33,\n",
              " 11,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 50,\n",
              " 11,\n",
              " 38,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 38,\n",
              " 39,\n",
              " 27,\n",
              " 34,\n",
              " 23,\n",
              " 11,\n",
              " 38,\n",
              " 37,\n",
              " 53,\n",
              " 16,\n",
              " 28,\n",
              " 34,\n",
              " 27,\n",
              " 33,\n",
              " 64,\n",
              " 47,\n",
              " 50,\n",
              " 16,\n",
              " 38,\n",
              " 37,\n",
              " 51,\n",
              " 16,\n",
              " 37,\n",
              " 50,\n",
              " 27,\n",
              " 37,\n",
              " 34,\n",
              " 47,\n",
              " 64,\n",
              " 58,\n",
              " 31,\n",
              " 37,\n",
              " 33,\n",
              " 47,\n",
              " 37,\n",
              " 50,\n",
              " 27,\n",
              " 38,\n",
              " 37,\n",
              " 51,\n",
              " 42,\n",
              " 28,\n",
              " 38,\n",
              " 16,\n",
              " 33,\n",
              " 27,\n",
              " 38,\n",
              " 37]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tokenized_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFAyA4zCWE-5",
        "outputId": "cdaf7148-f052-4339-bf70-e8b2d3df7a76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(359671, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKRl70HFTzG",
        "outputId": "0bb4b5f6-9ce1-4343-fad8-0fe3274f115a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([37, 16, 33, 37, 16, 50, 37, 27, 60, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVpLCKSZFXZO",
        "outputId": "3190fdba-8d31-43f9-b1fc-4dc2a7aa3492"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([63, 11, 62, 63,  5, 62, 45, 10, 20, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Zd2OkfQYs2Q7",
        "outputId": "8943c1dd-4c64-468d-bf00-0fbd50a4673c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │          \u001b[38;5;34m53,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)            │          \u001b[38;5;34m13,668\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">53,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,668</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,468\u001b[0m (263.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,468</span> (263.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,468\u001b[0m (263.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,468</span> (263.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(\"my_model.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQq1PHDkxDvN",
        "outputId": "3e2ef762-7a97-40f0-f275-9b84d6b8bcb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4471\n",
            " mean perplexity: 6.328146109095237 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 47ms/step - loss: 2.4469\n",
            "Epoch 2/20\n",
            "\u001b[1m1403/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9337\n",
            " mean perplexity: 5.5070156092433855 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 31ms/step - loss: 1.9337\n",
            "Epoch 3/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8283\n",
            " mean perplexity: 5.234252804468883 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 28ms/step - loss: 1.8283\n",
            "Epoch 4/20\n",
            "\u001b[1m1404/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7796\n",
            " mean perplexity: 5.063302159732111 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - loss: 1.7796\n",
            "Epoch 5/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7511\n",
            " mean perplexity: 4.9397505912016175 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - loss: 1.7511\n",
            "Epoch 6/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7332\n",
            " mean perplexity: 4.850132050456259 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - loss: 1.7332\n",
            "Epoch 7/20\n",
            "\u001b[1m1402/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7201\n",
            " mean perplexity: 4.8401270747646565 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - loss: 1.7201\n",
            "Epoch 8/20\n",
            "\u001b[1m1404/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7098\n",
            " mean perplexity: 4.783355303393414 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - loss: 1.7098\n",
            "Epoch 9/20\n",
            "\u001b[1m1402/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7009\n",
            " mean perplexity: 4.769578250837554 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - loss: 1.7009\n",
            "Epoch 10/20\n",
            "\u001b[1m1402/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6935\n",
            " mean perplexity: 4.712950091656482 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 27ms/step - loss: 1.6935\n",
            "Epoch 11/20\n",
            "\u001b[1m1403/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6888\n",
            " mean perplexity: 4.726077026794552 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 28ms/step - loss: 1.6888\n",
            "Epoch 12/20\n",
            "\u001b[1m1404/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6834\n",
            " mean perplexity: 4.7271808704556655 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - loss: 1.6834\n",
            "Epoch 13/20\n",
            "\u001b[1m1403/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6792\n",
            " mean perplexity: 4.6385019425618985 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - loss: 1.6792\n",
            "Epoch 14/20\n",
            "\u001b[1m1404/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6767\n",
            " mean perplexity: 4.6214843069543905 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - loss: 1.6767\n",
            "Epoch 15/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6726\n",
            " mean perplexity: 4.694081290469384 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 28ms/step - loss: 1.6726\n",
            "Epoch 16/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6688\n",
            " mean perplexity: 4.651072081780002 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - loss: 1.6688\n",
            "Epoch 17/20\n",
            "\u001b[1m1402/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6665\n",
            " mean perplexity: 4.641913281737445 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - loss: 1.6665\n",
            "Epoch 18/20\n",
            "\u001b[1m1404/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6648\n",
            " mean perplexity: 4.648609318276398 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 28ms/step - loss: 1.6648\n",
            "Epoch 19/20\n",
            "\u001b[1m1402/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6618\n",
            " mean perplexity: 4.6188358442489905 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 28ms/step - loss: 1.6618\n",
            "Epoch 20/20\n",
            "\u001b[1m1402/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6595\n",
            " mean perplexity: 4.5882592803702655 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 27ms/step - loss: 1.6595\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K30JHB3Dv-mx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "9d58d434-dcee-4574-a6c4-cd6d1426063a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IBvKHFPmzpy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db1cb36-8461-4a2b-aaa1-37d82bf298b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HNyBykvhzs7-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "ed4d03e9-58b8-48a9-dfb8-0611bbb8280f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://58a6087fee96d6c9cf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://58a6087fee96d6c9cf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://58a6087fee96d6c9cf.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9702ee68-0675-4ede-8fde-65c88714a221"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 de la caballeros de la caballero'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#la casa número 7 de saville\n",
        "input_text='la casa número 7 de'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"la casa número 7 de\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "P8HQoLhw-NYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a616f8-a411-48dc-fd04-24b025653a2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5, 45, 62, 22, 45, 49, 45, 62, 11, 56, 37, 63, 61, 20, 62, 41, 62,\n",
              "       31, 63, 49, 33, 18, 46, 49, 62, 31, 63, 62,  5, 45, 62, 63, 49, 30,\n",
              "       45, 22, 14, 51, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "salidas[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2S3_I3S1W1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb821424-fc71-44ee-b9e1-0952c8191781"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de la estación'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YricfELJeIOj",
        "outputId": "4f517cfe-a37c-40dd-832a-51269e946d92"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de la mañana, '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kRX_fgk3eITN",
        "outputId": "ee99d5c8-1264-463b-f7f5-98241e2b32af"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de la mañana. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IirbgeMleIXG",
        "outputId": "0579f4e7-7157-4d9e-af44-fa91b8241856"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de las ocho y '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qWo0aV96eIaz",
        "outputId": "13c1b46d-cbae-4a75-e557-b8097b5b129c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de las ocho de'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tx4fwE2leId3",
        "outputId": "d53830b2-33c9-49c2-b132-4f9f47606d0a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de haber despu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "318SQKo7eIgu",
        "outputId": "0611d3ca-589d-46b8-d050-1e612a915960"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de la parte de'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yJrpnOfEeIkF",
        "outputId": "3f9ec3a8-2d07-4fc1-dc45-4171c2542364"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de haber de la'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJtJ4kFJeInH",
        "outputId": "7a3a2ec3-cda9-4a97-b2e8-1e9c9a6baacc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de la mañana e'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vbWCCDeReIp2",
        "outputId": "0b18c387-aa8f-4e0b-9126-b6b60b51016f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la casa número 7 después de la mañana d'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODELO CON GRU"
      ],
      "metadata": {
        "id": "JkFMd-3QejX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = Sequential()\n",
        "\n",
        "model_gru.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_gru.add(GRU(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_gru.add(Dense(vocab_size, activation='softmax'))\n",
        "model_gru.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model_gru.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "htS_jkHRenf-",
        "outputId": "fd9d296b-95e1-4653-bf11-50bffaa1d023"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │         \u001b[38;5;34m162,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)            │          \u001b[38;5;34m13,668\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">162,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,668</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m175,668\u001b[0m (686.20 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,668</span> (686.20 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m175,668\u001b[0m (686.20 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,668</span> (686.20 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model_gru.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXYVa0_Xenim",
        "outputId": "44b29c7a-f103-4b70-a614-446d3aedf570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936ms/step - loss: 2.5123\n",
            " mean perplexity: 6.400793991464269 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1502s\u001b[0m 1s/step - loss: 2.5121\n",
            "Epoch 2/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927ms/step - loss: 1.8821\n",
            " mean perplexity: 5.169115139182655 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1507s\u001b[0m 1s/step - loss: 1.8820\n",
            "Epoch 3/20\n",
            "\u001b[1m 733/1405\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10:24\u001b[0m 929ms/step - loss: 1.7285"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Podemos graficar la evolución de la perplejidad con las épocas.\n",
        "# Recordar que el valor de perplejidad del modelo trivial es el tamaño del vocabulario.\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XS3GBIcMfbsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ],
      "metadata": {
        "id": "3tEX_FmzQXMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "3kNtRZxZQXPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = tok.texts_to_sequences([human_text])[0]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario la palabra\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    for word, index in tok.word_index.items():\n",
        "        if index == y_hat:\n",
        "            out_word = word\n",
        "            break\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + ' ' + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "_4TknZyvQXSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text='before i put my spell on'\n",
        "\n",
        "generate_seq(model, tok, input_text, max_length=max_context_size, n_words=3)"
      ],
      "metadata": {
        "id": "VPLbWIn-QXVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicción con beam search.\n",
        "# Se pueden camiar los modos entre 'det' (determinista) y\n",
        "# 'sto' (estocástico)\n",
        "# para el caso estocástico también se puede variar la temperatura\n",
        "salidas = beam_search(model,num_beams=10,num_words=6,input=\"before i put my spell on\",temp=1,mode='sto')"
      ],
      "metadata": {
        "id": "NWufeLOcSjGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tenemos `num_beams` salidas ordenadas de mayor a menor likelihood\n",
        "salidas.shape"
      ],
      "metadata": {
        "id": "mFqCe4tGSjKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ],
      "metadata": {
        "id": "eKQie1YZSjOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[1])"
      ],
      "metadata": {
        "id": "wxkU8OUSQXYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[2])"
      ],
      "metadata": {
        "id": "F288TK8NQXad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[3])"
      ],
      "metadata": {
        "id": "LXpQFD0RTT5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[4])"
      ],
      "metadata": {
        "id": "OGJSNYRoTT8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[5])"
      ],
      "metadata": {
        "id": "B9moKgCPTT-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[6])"
      ],
      "metadata": {
        "id": "1q3HArHiTYJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[7])"
      ],
      "metadata": {
        "id": "nOwRgs9YTYTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[8])"
      ],
      "metadata": {
        "id": "uGBnielBTUBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[9])"
      ],
      "metadata": {
        "id": "iwP1YSzjTeK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}