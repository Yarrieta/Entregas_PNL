{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yarrieta/Entregas_PNL/blob/Desafio3/3_modelo_lenguaje_char.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout, GRU\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7amy6uUaBLVD"
      },
      "outputs": [],
      "source": [
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [],
      "source": [
        "raw_html = urllib.request.urlopen('https://www.textos.info/julio-verne/la-vuelta-al-mundo-en-80-dias/ebook')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Parsear artículo, 'lxml' es el parser a utilizar\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "# Encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
        "# y tenerlos disponible como lista\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text + ' '\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "WBE0sSYuB-E6",
        "outputId": "b2298af3-335b-4663-e835-15e4f4911959"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' en el año 1872, la casa número 7 de saville-row, burlington gardens \\r\\n—donde murió sheridan en 1814— estaba habitada por phileas fogg, quien a\\r\\n pesar de que parecía haber tomado el partido de no hacer nada que \\r\\npudiese llamar la atención, era uno de los miembros más notables y \\r\\nsingulares del reformclub de londres. por consiguiente, phileas fogg, personaje enigmático y del cual sólo \\r\\nse sabía que era un hombre muy galante y de los más cumplidos gentlemen \\r\\nde la alta sociedad inglesa, sucedía a uno de los más grandes oradores \\r\\nque honran a inglaterra. decíase que se daba un aire a lo byron —su cabeza, se entiende, \\r\\nporque, en cuanto a los pies, no tenía defecto alguno—, pero a un byron \\r\\nde bigote y pastillas, a un byron impasible, que hubiera vivido mil años\\r\\n sin envejecer. phileas fogg, era inglés de pura cepa; pero quizás no había nacido en\\r\\n londres. jamás se le había visto en la bolsa ni en el banco, ni en \\r\\nninguno de los despachos mercantiles de la city. ni las dársenas '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_text = article_text.replace('\\n',' ')\n",
        "article_text = article_text.replace('\\r',' ')"
      ],
      "metadata": {
        "id": "ZuEmtMG2B38X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:3000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "fAanNYbiC-d_",
        "outputId": "72967efa-a56d-41a2-fba6-f7add377979e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" en el año 1872, la casa número 7 de saville-row, burlington gardens   —donde murió sheridan en 1814— estaba habitada por phileas fogg, quien a   pesar de que parecía haber tomado el partido de no hacer nada que   pudiese llamar la atención, era uno de los miembros más notables y   singulares del reformclub de londres. por consiguiente, phileas fogg, personaje enigmático y del cual sólo   se sabía que era un hombre muy galante y de los más cumplidos gentlemen   de la alta sociedad inglesa, sucedía a uno de los más grandes oradores   que honran a inglaterra. decíase que se daba un aire a lo byron —su cabeza, se entiende,   porque, en cuanto a los pies, no tenía defecto alguno—, pero a un byron   de bigote y pastillas, a un byron impasible, que hubiera vivido mil años   sin envejecer. phileas fogg, era inglés de pura cepa; pero quizás no había nacido en   londres. jamás se le había visto en la bolsa ni en el banco, ni en   ninguno de los despachos mercantiles de la city. ni las dársenas ni los   docks de londres recibieron nunca un navío cuyo armador fuese phileas   fogg. este gentleman no figuraba en ningún comité de administración. su   nombre nunca se había oído en un colegio de abogados, ni de en gray's   inn. nunca informó en la audiencia del canciller, ni en el banco de la   reina, ni en el echequer, ni en los tribunales eclesiásticos. no era ni   industrial, ni negociante, ni mercader, ni agricultor. no formaba parte   ni del instituto real de la gran bretaña ni del instituto de londres, ni   del instituto de los artistas, ni del instituto russel, ni del   instituto literario del oeste, ni del instituto de derecho, ni de ese   instituto de las ciencias y las artes reunidas que está colocado bajo la   protección de su graciosa majestad. en fin, no pertenecía a ninguna de   las numerosas sociedades que pueblan la capital de inglaterra, desde la   sociedad de la armónica hasta la sociedad entoniológica, fundada   principalmente con el fin de destruir los insectos nocivos. phileas fogg era miembro del reform-club, y nada más. al que hubiese extrañado que un gentleman tan misterioso alternase   con los miembros de esta digna asociación, se le podría haber respondido   que entró en ella recomendado por los señores baring hermanos. de aquí   cierta reputación debida a la regularidad con que sus cheques eran   pagados a la vista por el saldo de su cuenta corriente, invariablemente   acreedor. ¿era rico phileas fogg? indudablemente. cómo había realizado su   fortuna, es lo que los mejor informados no podían decir, y para saberlo,   el último a quien convenía dirigirse era míster fogg. en todo caso, aun   cuando no se prodigaba mucho, no era tampoco avaro, porque en cualquier   parte donde faltase auxilio para una cosa noble, útil o generosa, solía   prestarlo con sigilo y hasta con el velo del anónimo. en suma, encontrar algo que fuese menos comunicativo que este   gentleman, era cosa difícil. hablaba lo menos posible y parecía tanto   más misterioso\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwTK6xgLJd8q",
        "outputId": "e61819ed-5270-4b9e-e5cb-a7bc1e31d712"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLF_3VYIqKLh",
        "outputId": "0229db51-6ce8-4178-8bbf-714be1ef9e2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': 0,\n",
              " 'g': 1,\n",
              " '\\t': 2,\n",
              " '¡': 3,\n",
              " '7': 4,\n",
              " 'w': 5,\n",
              " 'a': 6,\n",
              " '<': 7,\n",
              " 'd': 8,\n",
              " 'ó': 9,\n",
              " '.': 10,\n",
              " '5': 11,\n",
              " 'í': 12,\n",
              " 'ü': 13,\n",
              " 't': 14,\n",
              " '-': 15,\n",
              " '(': 16,\n",
              " '2': 17,\n",
              " 'p': 18,\n",
              " '1': 19,\n",
              " 'f': 20,\n",
              " ';': 21,\n",
              " '6': 22,\n",
              " '\"': 23,\n",
              " '»': 24,\n",
              " 'j': 25,\n",
              " 'e': 26,\n",
              " 'k': 27,\n",
              " 'o': 28,\n",
              " 'u': 29,\n",
              " '4': 30,\n",
              " 'y': 31,\n",
              " '0': 32,\n",
              " ')': 33,\n",
              " 'è': 34,\n",
              " 'é': 35,\n",
              " '«': 36,\n",
              " 'l': 37,\n",
              " 'm': 38,\n",
              " '¿': 39,\n",
              " '~': 40,\n",
              " 'ñ': 41,\n",
              " '—': 42,\n",
              " ' ': 43,\n",
              " '3': 44,\n",
              " 'v': 45,\n",
              " 'r': 46,\n",
              " 'z': 47,\n",
              " \"'\": 48,\n",
              " 'h': 49,\n",
              " '8': 50,\n",
              " 's': 51,\n",
              " '9': 52,\n",
              " 'n': 53,\n",
              " 'x': 54,\n",
              " '/': 55,\n",
              " 'c': 56,\n",
              " 'q': 57,\n",
              " ':': 58,\n",
              " '?': 59,\n",
              " 'ú': 60,\n",
              " '!': 61,\n",
              " 'b': 62,\n",
              " 'á': 63,\n",
              " '>': 64,\n",
              " 'i': 65}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "char2idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwGVSKOiJ5bj",
        "outputId": "34a76796-9530-4d77-9a1e-9d05d37c9080"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[43,\n",
              " 26,\n",
              " 53,\n",
              " 43,\n",
              " 26,\n",
              " 37,\n",
              " 43,\n",
              " 6,\n",
              " 41,\n",
              " 28,\n",
              " 43,\n",
              " 19,\n",
              " 50,\n",
              " 4,\n",
              " 17,\n",
              " 0,\n",
              " 43,\n",
              " 37,\n",
              " 6,\n",
              " 43,\n",
              " 56,\n",
              " 6,\n",
              " 51,\n",
              " 6,\n",
              " 43,\n",
              " 53,\n",
              " 60,\n",
              " 38,\n",
              " 26,\n",
              " 46,\n",
              " 28,\n",
              " 43,\n",
              " 4,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 51,\n",
              " 6,\n",
              " 45,\n",
              " 65,\n",
              " 37,\n",
              " 37,\n",
              " 26,\n",
              " 15,\n",
              " 46,\n",
              " 28,\n",
              " 5,\n",
              " 0,\n",
              " 43,\n",
              " 62,\n",
              " 29,\n",
              " 46,\n",
              " 37,\n",
              " 65,\n",
              " 53,\n",
              " 1,\n",
              " 14,\n",
              " 28,\n",
              " 53,\n",
              " 43,\n",
              " 1,\n",
              " 6,\n",
              " 46,\n",
              " 8,\n",
              " 26,\n",
              " 53,\n",
              " 51,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 42,\n",
              " 8,\n",
              " 28,\n",
              " 53,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 38,\n",
              " 29,\n",
              " 46,\n",
              " 65,\n",
              " 9,\n",
              " 43,\n",
              " 51,\n",
              " 49,\n",
              " 26,\n",
              " 46,\n",
              " 65,\n",
              " 8,\n",
              " 6,\n",
              " 53,\n",
              " 43,\n",
              " 26,\n",
              " 53,\n",
              " 43,\n",
              " 19,\n",
              " 50,\n",
              " 19,\n",
              " 30,\n",
              " 42,\n",
              " 43,\n",
              " 26,\n",
              " 51,\n",
              " 14,\n",
              " 6,\n",
              " 62,\n",
              " 6,\n",
              " 43,\n",
              " 49,\n",
              " 6,\n",
              " 62,\n",
              " 65,\n",
              " 14,\n",
              " 6,\n",
              " 8,\n",
              " 6,\n",
              " 43,\n",
              " 18,\n",
              " 28,\n",
              " 46,\n",
              " 43,\n",
              " 18,\n",
              " 49,\n",
              " 65,\n",
              " 37,\n",
              " 26,\n",
              " 6,\n",
              " 51,\n",
              " 43,\n",
              " 20,\n",
              " 28,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 43,\n",
              " 57,\n",
              " 29,\n",
              " 65,\n",
              " 26,\n",
              " 53,\n",
              " 43,\n",
              " 6,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 18,\n",
              " 26,\n",
              " 51,\n",
              " 6,\n",
              " 46,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 57,\n",
              " 29,\n",
              " 26,\n",
              " 43,\n",
              " 18,\n",
              " 6,\n",
              " 46,\n",
              " 26,\n",
              " 56,\n",
              " 12,\n",
              " 6,\n",
              " 43,\n",
              " 49,\n",
              " 6,\n",
              " 62,\n",
              " 26,\n",
              " 46,\n",
              " 43,\n",
              " 14,\n",
              " 28,\n",
              " 38,\n",
              " 6,\n",
              " 8,\n",
              " 28,\n",
              " 43,\n",
              " 26,\n",
              " 37,\n",
              " 43,\n",
              " 18,\n",
              " 6,\n",
              " 46,\n",
              " 14,\n",
              " 65,\n",
              " 8,\n",
              " 28,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 53,\n",
              " 28,\n",
              " 43,\n",
              " 49,\n",
              " 6,\n",
              " 56,\n",
              " 26,\n",
              " 46,\n",
              " 43,\n",
              " 53,\n",
              " 6,\n",
              " 8,\n",
              " 6,\n",
              " 43,\n",
              " 57,\n",
              " 29,\n",
              " 26,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 18,\n",
              " 29,\n",
              " 8,\n",
              " 65,\n",
              " 26,\n",
              " 51,\n",
              " 26,\n",
              " 43,\n",
              " 37,\n",
              " 37,\n",
              " 6,\n",
              " 38,\n",
              " 6,\n",
              " 46,\n",
              " 43,\n",
              " 37,\n",
              " 6,\n",
              " 43,\n",
              " 6,\n",
              " 14,\n",
              " 26,\n",
              " 53,\n",
              " 56,\n",
              " 65,\n",
              " 9,\n",
              " 53,\n",
              " 0,\n",
              " 43,\n",
              " 26,\n",
              " 46,\n",
              " 6,\n",
              " 43,\n",
              " 29,\n",
              " 53,\n",
              " 28,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 37,\n",
              " 28,\n",
              " 51,\n",
              " 43,\n",
              " 38,\n",
              " 65,\n",
              " 26,\n",
              " 38,\n",
              " 62,\n",
              " 46,\n",
              " 28,\n",
              " 51,\n",
              " 43,\n",
              " 38,\n",
              " 63,\n",
              " 51,\n",
              " 43,\n",
              " 53,\n",
              " 28,\n",
              " 14,\n",
              " 6,\n",
              " 62,\n",
              " 37,\n",
              " 26,\n",
              " 51,\n",
              " 43,\n",
              " 31,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 51,\n",
              " 65,\n",
              " 53,\n",
              " 1,\n",
              " 29,\n",
              " 37,\n",
              " 6,\n",
              " 46,\n",
              " 26,\n",
              " 51,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 37,\n",
              " 43,\n",
              " 46,\n",
              " 26,\n",
              " 20,\n",
              " 28,\n",
              " 46,\n",
              " 38,\n",
              " 56,\n",
              " 37,\n",
              " 29,\n",
              " 62,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 37,\n",
              " 28,\n",
              " 53,\n",
              " 8,\n",
              " 46,\n",
              " 26,\n",
              " 51,\n",
              " 10,\n",
              " 43,\n",
              " 18,\n",
              " 28,\n",
              " 46,\n",
              " 43,\n",
              " 56,\n",
              " 28,\n",
              " 53,\n",
              " 51,\n",
              " 65,\n",
              " 1,\n",
              " 29,\n",
              " 65,\n",
              " 26,\n",
              " 53,\n",
              " 14,\n",
              " 26,\n",
              " 0,\n",
              " 43,\n",
              " 18,\n",
              " 49,\n",
              " 65,\n",
              " 37,\n",
              " 26,\n",
              " 6,\n",
              " 51,\n",
              " 43,\n",
              " 20,\n",
              " 28,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 43,\n",
              " 18,\n",
              " 26,\n",
              " 46,\n",
              " 51,\n",
              " 28,\n",
              " 53,\n",
              " 6,\n",
              " 25,\n",
              " 26,\n",
              " 43,\n",
              " 26,\n",
              " 53,\n",
              " 65,\n",
              " 1,\n",
              " 38,\n",
              " 63,\n",
              " 14,\n",
              " 65,\n",
              " 56,\n",
              " 28,\n",
              " 43,\n",
              " 31,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 37,\n",
              " 43,\n",
              " 56,\n",
              " 29,\n",
              " 6,\n",
              " 37,\n",
              " 43,\n",
              " 51,\n",
              " 9,\n",
              " 37,\n",
              " 28,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 51,\n",
              " 26,\n",
              " 43,\n",
              " 51,\n",
              " 6,\n",
              " 62,\n",
              " 12,\n",
              " 6,\n",
              " 43,\n",
              " 57,\n",
              " 29,\n",
              " 26,\n",
              " 43,\n",
              " 26,\n",
              " 46,\n",
              " 6,\n",
              " 43,\n",
              " 29,\n",
              " 53,\n",
              " 43,\n",
              " 49,\n",
              " 28,\n",
              " 38,\n",
              " 62,\n",
              " 46,\n",
              " 26,\n",
              " 43,\n",
              " 38,\n",
              " 29,\n",
              " 31,\n",
              " 43,\n",
              " 1,\n",
              " 6,\n",
              " 37,\n",
              " 6,\n",
              " 53,\n",
              " 14,\n",
              " 26,\n",
              " 43,\n",
              " 31,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 37,\n",
              " 28,\n",
              " 51,\n",
              " 43,\n",
              " 38,\n",
              " 63,\n",
              " 51,\n",
              " 43,\n",
              " 56,\n",
              " 29,\n",
              " 38,\n",
              " 18,\n",
              " 37,\n",
              " 65,\n",
              " 8,\n",
              " 28,\n",
              " 51,\n",
              " 43,\n",
              " 1,\n",
              " 26,\n",
              " 53,\n",
              " 14,\n",
              " 37,\n",
              " 26,\n",
              " 38,\n",
              " 26,\n",
              " 53,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 37,\n",
              " 6,\n",
              " 43,\n",
              " 6,\n",
              " 37,\n",
              " 14,\n",
              " 6,\n",
              " 43,\n",
              " 51,\n",
              " 28,\n",
              " 56,\n",
              " 65,\n",
              " 26,\n",
              " 8,\n",
              " 6,\n",
              " 8,\n",
              " 43,\n",
              " 65,\n",
              " 53,\n",
              " 1,\n",
              " 37,\n",
              " 26,\n",
              " 51,\n",
              " 6,\n",
              " 0,\n",
              " 43,\n",
              " 51,\n",
              " 29,\n",
              " 56,\n",
              " 26,\n",
              " 8,\n",
              " 12,\n",
              " 6,\n",
              " 43,\n",
              " 6,\n",
              " 43,\n",
              " 29,\n",
              " 53,\n",
              " 28,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 37,\n",
              " 28,\n",
              " 51,\n",
              " 43,\n",
              " 38,\n",
              " 63,\n",
              " 51,\n",
              " 43,\n",
              " 1,\n",
              " 46,\n",
              " 6,\n",
              " 53,\n",
              " 8,\n",
              " 26,\n",
              " 51,\n",
              " 43,\n",
              " 28,\n",
              " 46,\n",
              " 6,\n",
              " 8,\n",
              " 28,\n",
              " 46,\n",
              " 26,\n",
              " 51,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 57,\n",
              " 29,\n",
              " 26,\n",
              " 43,\n",
              " 49,\n",
              " 28,\n",
              " 53,\n",
              " 46,\n",
              " 6,\n",
              " 53,\n",
              " 43,\n",
              " 6,\n",
              " 43,\n",
              " 65,\n",
              " 53,\n",
              " 1,\n",
              " 37,\n",
              " 6,\n",
              " 14,\n",
              " 26,\n",
              " 46,\n",
              " 46,\n",
              " 6,\n",
              " 10,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 56,\n",
              " 12,\n",
              " 6,\n",
              " 51,\n",
              " 26,\n",
              " 43,\n",
              " 57,\n",
              " 29,\n",
              " 26,\n",
              " 43,\n",
              " 51,\n",
              " 26,\n",
              " 43,\n",
              " 8,\n",
              " 6,\n",
              " 62,\n",
              " 6,\n",
              " 43,\n",
              " 29,\n",
              " 53,\n",
              " 43,\n",
              " 6,\n",
              " 65,\n",
              " 46,\n",
              " 26,\n",
              " 43,\n",
              " 6,\n",
              " 43,\n",
              " 37,\n",
              " 28,\n",
              " 43,\n",
              " 62,\n",
              " 31,\n",
              " 46,\n",
              " 28,\n",
              " 53,\n",
              " 43,\n",
              " 42,\n",
              " 51,\n",
              " 29,\n",
              " 43,\n",
              " 56,\n",
              " 6,\n",
              " 62,\n",
              " 26,\n",
              " 47,\n",
              " 6,\n",
              " 0,\n",
              " 43,\n",
              " 51,\n",
              " 26,\n",
              " 43,\n",
              " 26,\n",
              " 53,\n",
              " 14,\n",
              " 65,\n",
              " 26,\n",
              " 53,\n",
              " 8,\n",
              " 26,\n",
              " 0,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 18,\n",
              " 28,\n",
              " 46,\n",
              " 57,\n",
              " 29,\n",
              " 26,\n",
              " 0,\n",
              " 43,\n",
              " 26,\n",
              " 53,\n",
              " 43,\n",
              " 56,\n",
              " 29,\n",
              " 6,\n",
              " 53,\n",
              " 14,\n",
              " 28,\n",
              " 43,\n",
              " 6,\n",
              " 43,\n",
              " 37,\n",
              " 28,\n",
              " 51,\n",
              " 43,\n",
              " 18,\n",
              " 65,\n",
              " 26,\n",
              " 51,\n",
              " 0,\n",
              " 43,\n",
              " 53,\n",
              " 28,\n",
              " 43,\n",
              " 14,\n",
              " 26,\n",
              " 53,\n",
              " 12,\n",
              " 6,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 20,\n",
              " 26,\n",
              " 56,\n",
              " 14,\n",
              " 28,\n",
              " 43,\n",
              " 6,\n",
              " 37,\n",
              " 1,\n",
              " 29,\n",
              " 53,\n",
              " 28,\n",
              " 42,\n",
              " 0,\n",
              " 43,\n",
              " 18,\n",
              " 26,\n",
              " 46,\n",
              " 28,\n",
              " 43,\n",
              " 6,\n",
              " 43,\n",
              " 29,\n",
              " 53,\n",
              " 43,\n",
              " 62,\n",
              " 31,\n",
              " 46,\n",
              " 28,\n",
              " 53,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 62,\n",
              " 65,\n",
              " 1,\n",
              " 28,\n",
              " 14,\n",
              " 26,\n",
              " 43,\n",
              " 31,\n",
              " 43,\n",
              " 18,\n",
              " 6,\n",
              " 51,\n",
              " 14,\n",
              " 65,\n",
              " 37,\n",
              " 37,\n",
              " 6,\n",
              " 51,\n",
              " 0,\n",
              " 43,\n",
              " 6,\n",
              " 43,\n",
              " 29,\n",
              " 53,\n",
              " 43,\n",
              " 62,\n",
              " 31,\n",
              " 46,\n",
              " 28,\n",
              " 53,\n",
              " 43,\n",
              " 65,\n",
              " 38,\n",
              " 18,\n",
              " 6,\n",
              " 51,\n",
              " 65,\n",
              " 62,\n",
              " 37,\n",
              " 26,\n",
              " 0,\n",
              " 43,\n",
              " 57,\n",
              " 29,\n",
              " 26,\n",
              " 43,\n",
              " 49,\n",
              " 29,\n",
              " 62,\n",
              " 65,\n",
              " 26,\n",
              " 46,\n",
              " 6,\n",
              " 43,\n",
              " 45,\n",
              " 65,\n",
              " 45,\n",
              " 65,\n",
              " 8,\n",
              " 28,\n",
              " 43,\n",
              " 38,\n",
              " 65,\n",
              " 37,\n",
              " 43,\n",
              " 6,\n",
              " 41,\n",
              " 28,\n",
              " 51,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 51,\n",
              " 65,\n",
              " 53,\n",
              " 43,\n",
              " 26,\n",
              " 53,\n",
              " 45,\n",
              " 26,\n",
              " 25,\n",
              " 26,\n",
              " 56,\n",
              " 26,\n",
              " 46,\n",
              " 10,\n",
              " 43,\n",
              " 18,\n",
              " 49,\n",
              " 65,\n",
              " 37,\n",
              " 26,\n",
              " 6,\n",
              " 51,\n",
              " 43,\n",
              " 20,\n",
              " 28,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 43,\n",
              " 26,\n",
              " 46,\n",
              " 6,\n",
              " 43,\n",
              " 65,\n",
              " 53,\n",
              " 1,\n",
              " 37,\n",
              " 35,\n",
              " 51,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 18,\n",
              " 29,\n",
              " 46,\n",
              " 6,\n",
              " 43,\n",
              " 56,\n",
              " 26,\n",
              " 18,\n",
              " 6,\n",
              " 21,\n",
              " 43,\n",
              " 18,\n",
              " 26,\n",
              " 46,\n",
              " 28,\n",
              " 43,\n",
              " 57,\n",
              " 29,\n",
              " 65,\n",
              " 47,\n",
              " 63,\n",
              " 51,\n",
              " 43,\n",
              " 53,\n",
              " 28,\n",
              " 43,\n",
              " 49,\n",
              " 6,\n",
              " 62,\n",
              " 12,\n",
              " 6,\n",
              " 43,\n",
              " 53,\n",
              " 6,\n",
              " 56,\n",
              " 65,\n",
              " 8,\n",
              " 28,\n",
              " 43,\n",
              " 26,\n",
              " 53,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 37,\n",
              " 28,\n",
              " 53,\n",
              " 8,\n",
              " 46,\n",
              " 26,\n",
              " 51,\n",
              " 10,\n",
              " 43,\n",
              " 25,\n",
              " 6,\n",
              " 38,\n",
              " 63,\n",
              " 51,\n",
              " 43,\n",
              " 51,\n",
              " 26,\n",
              " 43,\n",
              " 37,\n",
              " 26,\n",
              " 43,\n",
              " 49,\n",
              " 6,\n",
              " 62,\n",
              " 12,\n",
              " 6,\n",
              " 43,\n",
              " 45,\n",
              " 65,\n",
              " 51,\n",
              " 14,\n",
              " 28,\n",
              " 43,\n",
              " 26,\n",
              " 53,\n",
              " 43,\n",
              " 37,\n",
              " 6,\n",
              " 43,\n",
              " 62,\n",
              " 28,\n",
              " 37,\n",
              " 51,\n",
              " 6,\n",
              " 43,\n",
              " 53,\n",
              " 65,\n",
              " 43,\n",
              " 26,\n",
              " 53,\n",
              " 43,\n",
              " 26,\n",
              " 37,\n",
              " 43,\n",
              " 62,\n",
              " 6,\n",
              " 53,\n",
              " 56,\n",
              " 28,\n",
              " 0,\n",
              " 43,\n",
              " 53,\n",
              " 65,\n",
              " 43,\n",
              " 26,\n",
              " 53,\n",
              " 43,\n",
              " 43,\n",
              " 43,\n",
              " 53,\n",
              " 65,\n",
              " 53,\n",
              " 1,\n",
              " 29,\n",
              " 53,\n",
              " 28,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 37,\n",
              " 28,\n",
              " 51,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 51,\n",
              " 18,\n",
              " 6,\n",
              " 56,\n",
              " 49,\n",
              " 28,\n",
              " 51,\n",
              " 43,\n",
              " 38,\n",
              " 26,\n",
              " 46,\n",
              " 56,\n",
              " 6,\n",
              " 53,\n",
              " 14,\n",
              " 65,\n",
              " 37,\n",
              " 26,\n",
              " 51,\n",
              " 43,\n",
              " 8,\n",
              " 26,\n",
              " 43,\n",
              " 37,\n",
              " 6,\n",
              " 43,\n",
              " 56,\n",
              " 65,\n",
              " 14,\n",
              " 31,\n",
              " 10,\n",
              " 43,\n",
              " 53,\n",
              " 65,\n",
              " 43,\n",
              " 37,\n",
              " 6,\n",
              " 51,\n",
              " 43,\n",
              " 8,\n",
              " 63,\n",
              " 46,\n",
              " 51,\n",
              " 26,\n",
              " 53,\n",
              " 6,\n",
              " 51,\n",
              " 43]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tokenized_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFAyA4zCWE-5",
        "outputId": "720e5c60-2787-41d2-9b11-ed37b6b6f571"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(359671, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKRl70HFTzG",
        "outputId": "94587b95-b352-43b0-d382-1d8bd6712a6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([43, 26, 53, 43, 26, 37, 43,  6, 41, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVpLCKSZFXZO",
        "outputId": "aa9a6dbf-9284-47d6-ce75-47ee07277b62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([26, 53, 43, 26, 37, 43,  6, 41, 28, 43])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Zd2OkfQYs2Q7",
        "outputId": "38508451-c8b2-4881-ac22-018fc3272beb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │          \u001b[38;5;34m53,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)            │          \u001b[38;5;34m13,266\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">53,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,266</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,666\u001b[0m (260.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,666</span> (260.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,666\u001b[0m (260.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,666</span> (260.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(\"my_model.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQq1PHDkxDvN",
        "outputId": "c80a78bb-2219-4078-f782-bb8286eeb57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: 2.4320\n",
            " mean perplexity: 6.408834478300257 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 451ms/step - loss: 2.4318\n",
            "Epoch 2/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 1.9241\n",
            " mean perplexity: 5.5517679191772515 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m641s\u001b[0m 457ms/step - loss: 1.9241\n",
            "Epoch 3/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 1.8181\n",
            " mean perplexity: 5.235141046918059 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 434ms/step - loss: 1.8180\n",
            "Epoch 4/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 1.7694\n",
            " mean perplexity: 5.136374881789337 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 439ms/step - loss: 1.7694\n",
            "Epoch 5/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 1.7429\n",
            " mean perplexity: 4.977523756802655 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 439ms/step - loss: 1.7429\n",
            "Epoch 6/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 1.7248\n",
            " mean perplexity: 4.959881704878976 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 446ms/step - loss: 1.7248\n",
            "Epoch 7/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 1.7108\n",
            " mean perplexity: 4.887085689100899 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 425ms/step - loss: 1.7108\n",
            "Epoch 8/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 1.7016\n",
            " mean perplexity: 4.835885953936084 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 443ms/step - loss: 1.7016\n",
            "Epoch 9/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 1.6928\n",
            " mean perplexity: 4.831673781934417 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 440ms/step - loss: 1.6928\n",
            "Epoch 10/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 1.6864\n",
            " mean perplexity: 4.83336872309224 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 437ms/step - loss: 1.6864\n",
            "Epoch 11/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 1.6816\n",
            " mean perplexity: 4.773861142616083 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 424ms/step - loss: 1.6816\n",
            "Epoch 12/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 1.6754\n",
            " mean perplexity: 4.721143267100161 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 423ms/step - loss: 1.6754\n",
            "Epoch 13/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 1.6714\n",
            " mean perplexity: 4.70534409809253 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 426ms/step - loss: 1.6714\n",
            "Epoch 14/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 1.6676\n",
            " mean perplexity: 4.6982936689948485 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 434ms/step - loss: 1.6676\n",
            "Epoch 15/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 1.6645\n",
            " mean perplexity: 4.64644382038822 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 441ms/step - loss: 1.6645\n",
            "Epoch 16/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 1.6618\n",
            " mean perplexity: 4.671764897621517 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 427ms/step - loss: 1.6618\n",
            "Epoch 17/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 1.6611\n",
            " mean perplexity: 4.652565642058365 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 437ms/step - loss: 1.6611\n",
            "Epoch 18/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 1.6573\n",
            " mean perplexity: 4.62474129965298 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 436ms/step - loss: 1.6573\n",
            "Epoch 19/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 1.6552\n",
            " mean perplexity: 4.633213422646802 \n",
            "\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 433ms/step - loss: 1.6552\n",
            "Epoch 20/20\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 1.6538\n",
            " mean perplexity: 4.581611856530661 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 440ms/step - loss: 1.6538\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "K30JHB3Dv-mx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "deb2acfa-e709-4644-863a-85f0f5e92dd2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IBvKHFPmzpy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688c1789-2448-428c-93c1-a54ae18f9f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio\n",
        "\n",
        "#sentencia= de los más cumplidos gentlemen de la alta sociedad [inglesa]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "HNyBykvhzs7-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "e90f87d5-4df7-42ac-bf44-42f9c1371b82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://0d915e1f5b51b52632.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0d915e1f5b51b52632.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://0d915e1f5b51b52632.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "36f57e12-337f-4587-9a68-bca4374dad42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de la cabeza de la cabeza de '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "#la casa número 7 de saville\n",
        "input_text='de los más cumplidos gentlemen de la alta sociedad'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"de los más cumplidos gentlemen de la alta sociedad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "P8HQoLhw-NYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4af2105-d273-4a5b-c45b-5863962084e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8, 26, 43, 37, 28, 51, 43, 38, 63, 51, 43, 56, 29, 38, 18, 37, 65,\n",
              "        8, 28, 51, 43,  1, 26, 53, 14, 37, 26, 38, 26, 53, 43,  8, 26, 43,\n",
              "       37,  6, 43,  6, 37, 14,  6, 43, 51, 28, 56, 65, 26,  8,  6,  8, 43,\n",
              "        8, 26, 43, 37,  6, 43, 26, 51, 14,  6, 56, 65,  9, 53, 43,  8, 26,\n",
              "       43, 37])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "salidas[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "2S3_I3S1W1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb2a3010-d542-494c-fd5c-32bc80eaabf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de la estación de l'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YricfELJeIOj",
        "outputId": "6fff4866-776e-4b80-e358-e7f9cbba7e46"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de los viajeros de '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kRX_fgk3eITN",
        "outputId": "18050e0e-8d24-4361-e79d-0c684189151d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de la estación del '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IirbgeMleIXG",
        "outputId": "7b00e558-b42a-45bb-95c3-88d390568b10"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de la estación de p'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qWo0aV96eIaz",
        "outputId": "19919833-29f0-4990-a5c6-fb44edd07574"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de picaporte se hab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tx4fwE2leId3",
        "outputId": "7c1e0afd-e563-47d5-9adc-53b94b1aaf00"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de picaporte, que n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "318SQKo7eIgu",
        "outputId": "fddf763d-fc30-4080-d57f-1b63b1f85089"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de la estación de  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yJrpnOfEeIkF",
        "outputId": "c94e7876-77fa-4930-cb11-fc8428caf824"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de la estación de s'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJtJ4kFJeInH",
        "outputId": "97058f3c-81c9-46f7-f5a3-a67d7cbb1bca"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de picaporte, que e'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#veamos las salidas\n",
        "decode(salidas[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vbWCCDeReIp2",
        "outputId": "89a9ecef-c5e7-4f5e-ec7e-10747354cf82"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de los más cumplidos gentlemen de la alta sociedad de los viajeros en '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODELO CON GRU"
      ],
      "metadata": {
        "id": "JkFMd-3QejX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = Sequential()\n",
        "\n",
        "model_gru.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_gru.add(GRU(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_gru.add(Dense(vocab_size, activation='softmax'))\n",
        "model_gru.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model_gru.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "htS_jkHRenf-",
        "outputId": "85f888c7-8d0c-4e2d-8e7a-1602ab777980"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │         \u001b[38;5;34m160,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)            │          \u001b[38;5;34m13,266\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">160,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,266</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m174,066\u001b[0m (679.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,066</span> (679.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m174,066\u001b[0m (679.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,066</span> (679.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model_gru.fit(X, y, epochs=15, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXYVa0_Xenim",
        "outputId": "9daa43be-2f2d-49e8-b1d8-1f3c07286cf6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876ms/step - loss: 2.4973\n",
            " mean perplexity: 6.286812855516326 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1438s\u001b[0m 1s/step - loss: 2.4971\n",
            "Epoch 2/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866ms/step - loss: 1.8729\n",
            " mean perplexity: 5.069012630550833 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1408s\u001b[0m 982ms/step - loss: 1.8729\n",
            "Epoch 3/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857ms/step - loss: 1.7037\n",
            " mean perplexity: 4.61116362038159 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1428s\u001b[0m 1s/step - loss: 1.7037\n",
            "Epoch 4/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891ms/step - loss: 1.6259\n",
            " mean perplexity: 4.439326498376672 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1479s\u001b[0m 1s/step - loss: 1.6259\n",
            "Epoch 5/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901ms/step - loss: 1.5808\n",
            " mean perplexity: 4.334212827479653 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1475s\u001b[0m 1s/step - loss: 1.5808\n",
            "Epoch 6/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907ms/step - loss: 1.5509\n",
            " mean perplexity: 4.2622887758880745 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1472s\u001b[0m 1s/step - loss: 1.5509\n",
            "Epoch 7/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899ms/step - loss: 1.5302\n",
            " mean perplexity: 4.203162770081114 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1466s\u001b[0m 1s/step - loss: 1.5302\n",
            "Epoch 8/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891ms/step - loss: 1.5153\n",
            " mean perplexity: 4.16853638627659 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1477s\u001b[0m 1s/step - loss: 1.5153\n",
            "Epoch 9/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894ms/step - loss: 1.5032\n",
            " mean perplexity: 4.153015891548956 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1499s\u001b[0m 1s/step - loss: 1.5032\n",
            "Epoch 10/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889ms/step - loss: 1.4913\n",
            " mean perplexity: 4.116607812288777 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1420s\u001b[0m 1s/step - loss: 1.4913\n",
            "Epoch 11/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898ms/step - loss: 1.4827\n",
            " mean perplexity: 4.066725122671633 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1476s\u001b[0m 1s/step - loss: 1.4827\n",
            "Epoch 12/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913ms/step - loss: 1.4750\n",
            " mean perplexity: 4.034873864279095 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1513s\u001b[0m 1s/step - loss: 1.4750\n",
            "Epoch 13/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916ms/step - loss: 1.4678\n",
            " mean perplexity: 4.002060388972621 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1526s\u001b[0m 1s/step - loss: 1.4678\n",
            "Epoch 14/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915ms/step - loss: 1.4612\n",
            " mean perplexity: 3.99002003202489 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 1s/step - loss: 1.4612\n",
            "Epoch 15/15\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909ms/step - loss: 1.4562\n",
            " mean perplexity: 3.9782259693102344 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1480s\u001b[0m 1s/step - loss: 1.4562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Podemos graficar la evolución de la perplejidad con las épocas.\n",
        "# Recordar que el valor de perplejidad del modelo trivial es el tamaño del vocabulario.\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "XS3GBIcMfbsI",
        "outputId": "cad7a7ac-d972-4fa8-e427-387a7f2791d0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ],
      "metadata": {
        "id": "3tEX_FmzQXMG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "3kNtRZxZQXPl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "_4TknZyvQXSm",
        "outputId": "7b4baaa5-9a64-442c-844c-a98fa81ad199"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://906e8f9956beddabda.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://906e8f9956beddabda.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://906e8f9956beddabda.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text='no formaba parte ni del instituto real de la gran bretañ'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VPLbWIn-QXVV",
        "outputId": "cb27a54f-66af-4111-8f2a-843f21019b96"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no formaba parte ni del instituto real de la gran bretaña de la compañía de la compañí'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicción con beam search.\n",
        "# Se pueden camiar los modos entre 'det' (determinista) y\n",
        "# 'sto' (estocástico)\n",
        "# para el caso estocástico también se puede variar la temperatura\n",
        "salidas = beam_search(model,num_beams=10,num_words=15,input=\"este gentleman no figuraba en ningún comité de administració\",temp=1,mode='sto')"
      ],
      "metadata": {
        "id": "NWufeLOcSjGE"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tenemos `num_beams` salidas ordenadas de mayor a menor likelihood\n",
        "salidas.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFqCe4tGSjKC",
        "outputId": "e69bd6e5-c09b-410e-aef2-b0a511efa196"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 75)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eKQie1YZSjOO",
        "outputId": "14e12e4a-d33a-47d1-d705-147795edaf04"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de la estació'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wxkU8OUSQXYP",
        "outputId": "e0b50d15-1daa-495a-eb9f-447b95bd722a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de la estació'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F288TK8NQXad",
        "outputId": "fac9fa15-259a-435f-b2d8-886ea269a775"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de la estació'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LXpQFD0RTT5Z",
        "outputId": "6e8eff09-01b0-42dd-e4b2-ba8e4dcf1bf8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de los viajer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OGJSNYRoTT8U",
        "outputId": "b34db339-da00-4621-8526-9a20ba15d939"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de la estació'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B9moKgCPTT-3",
        "outputId": "796f1e13-bca6-4faa-8c86-f7dcdf29c42d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de la estació'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1q3HArHiTYJe",
        "outputId": "3cac8e0c-6766-47d6-9729-232ded3427c9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de la estació'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nOwRgs9YTYTl",
        "outputId": "92b89c82-ee24-4d8f-e24c-012a2236a96b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de la estació'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uGBnielBTUBp",
        "outputId": "e181f472-0485-4442-a663-15c3e65cb1e2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de la estació'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iwP1YSzjTeK5",
        "outputId": "669b7cbd-8f49-4d18-cb52-3bfc8fb95b7a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este gentleman no figuraba en ningún comité de administración de la estació'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": [
        "* Se observa que el modelo GRU tiene mejor desempeño con 15 épocas con respecto a Simple RNN con 20 épocas. En el modelo GRU se observa que se completa correctamente el carácter faltante."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}